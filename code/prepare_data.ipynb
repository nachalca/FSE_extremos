{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to prepare the data to be used in future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                       \n",
    "import xarray as xr                      \n",
    "import pandas as pd     \n",
    "import cftime           \n",
    "import zipfile       \n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_nc = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_t2m_horario_2000a2010_uy.nc')\n",
    "reanalysis_nc_2 = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_t2m_horario_2011a2021_uy.nc')\n",
    "\n",
    "def transform_reanalysis(data_nc):\n",
    "    reanalysis = pd.DataFrame()\n",
    "    reanalysis['time'] = pd.to_datetime(data_nc.time)\n",
    "    reanalysis['tas'] = data_nc.t2m.mean(dim=[\"latitude\",\"longitude\"]) \n",
    "    reanalysis = reanalysis.loc[reanalysis[\"time\"] < datetime.fromisoformat('2015-01-01T00:00:00')]\n",
    "    reanalysis['date'] = reanalysis['time'].dt.date\n",
    "    reanalysis['day'] = reanalysis['time'].dt.day\n",
    "    reanalysis['month'] = reanalysis['time'].dt.month\n",
    "    reanalysis_by_day = reanalysis[[\"date\", \"tas\"]].groupby('date') \\\n",
    "                                                   .mean() \\\n",
    "                                                   .rename(columns={\"tas\":\"tas_daily\"})\n",
    "    reanalysis = reanalysis.join(reanalysis_by_day, on=\"date\") \\\n",
    "                            .drop('date', axis=1)\n",
    "    return reanalysis\n",
    "\n",
    "reanalysis = pd.concat([transform_reanalysis(reanalysis_nc), transform_reanalysis(reanalysis_nc_2)])\n",
    "reanalysis = reanalysis[((reanalysis['day'] != 29) | (reanalysis['month'] != 2))] #Delete all Feb 29th \n",
    "reanalysis = reanalysis[['time', 'tas_daily', 'tas']] #select the variables we want to keep\n",
    "reanalysis.to_csv('reanalysis_tas_training_data.csv',  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data to be downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CESM2_WACCM_nc = xr.open_dataset('../data/tas_day_CESM2-WACCM_historical_r1i1p1f1_gn_20000101-20141231_v20190227.nc')\n",
    "CESM2_WACCM = pd.DataFrame()\n",
    "CESM2_WACCM['time'] = CESM2_WACCM_nc.time\n",
    "CESM2_WACCM['CESM2_WACCM'] = CESM2_WACCM_nc.tas.mean(dim=[\"lat\",\"lon\"])\n",
    "CESM2_WACCM['time'] = CESM2_WACCM['time'].apply(lambda x: datetime.fromisoformat(x.isoformat()))\n",
    "\n",
    "CESM2_WACCM_by_hour = []\n",
    "\n",
    "for row in CESM2_WACCM.values:\n",
    "    for h in range(0,24):\n",
    "        new_row = pd.Series({\n",
    "            'time': row[0] + timedelta(hours=h),\n",
    "            'tas': 0,\n",
    "            'tas_daily': row[1]\n",
    "        })\n",
    "        CESM2_WACCM_by_hour.append(new_row)\n",
    "\n",
    "CESM2_WACCM = pd.DataFrame(CESM2_WACCM_by_hour)\n",
    "CESM2_WACCM.to_csv('cmip6_tas_to_downscale_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I've assumed that sfcwind = sqrt(u^2 + v^2). Corroboration is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     reanalysis \u001b[39m=\u001b[39m reanalysis\u001b[39m.\u001b[39mjoin(reanalysis_by_day, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                             \u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m reanalysis\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m reanalysis_wind \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([transform_reanalysis_wind(reanalysis_wind_U_nc, reanalysis_wind_V_nc), \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                              transform_reanalysis_wind(reanalysis_wind_U_2_nc, reanalysis_wind_V_2_nc)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m reanalysis_wind \u001b[39m=\u001b[39m reanalysis_wind[((reanalysis_wind[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m29\u001b[39m) \u001b[39m|\u001b[39m (reanalysis_wind[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m))] \u001b[39m#Delete all Feb 29th \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m reanalysis_wind \u001b[39m=\u001b[39m reanalysis_wind[[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msfcWind_daily\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msfcWind\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m#select the variables we want to keep\u001b[39;00m\n",
      "\u001b[1;32m/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m reanalysis \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reanalysis[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(U_nc\u001b[39m.\u001b[39mtime)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m reanalysis[\u001b[39m'\u001b[39m\u001b[39msfcWind\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39msquare(U_nc\u001b[39m.\u001b[39mu10) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49msquare(V_nc\u001b[39m.\u001b[39;49mv10)) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                            \u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m\"\u001b[39m]) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m reanalysis \u001b[39m=\u001b[39m reanalysis\u001b[39m.\u001b[39mloc[reanalysis[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m datetime\u001b[39m.\u001b[39mfromisoformat(\u001b[39m'\u001b[39m\u001b[39m2015-01-01T00:00:00\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tancre/dev/UTE/FSE_extremos/code/prepare_data.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m reanalysis[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m reanalysis[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate\n",
      "File \u001b[0;32m~/bin/miniconda3/lib/python3.11/site-packages/xarray/core/arithmetic.py:83\u001b[0m, in \u001b[0;36mSupportsArithmetic.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mxarray objects are not yet supported in the `out` argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor ufuncs. As an alternative, consider explicitly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconverting xarray objects to NumPy arrays (e.g., with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.values`).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m join \u001b[39m=\u001b[39m dataset_join \u001b[39m=\u001b[39m OPTIONS[\u001b[39m\"\u001b[39m\u001b[39marithmetic_join\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m apply_ufunc(\n\u001b[1;32m     84\u001b[0m     ufunc,\n\u001b[1;32m     85\u001b[0m     \u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m     86\u001b[0m     input_core_dims\u001b[39m=\u001b[39;49m((),) \u001b[39m*\u001b[39;49m ufunc\u001b[39m.\u001b[39;49mnin,\n\u001b[1;32m     87\u001b[0m     output_core_dims\u001b[39m=\u001b[39;49m((),) \u001b[39m*\u001b[39;49m ufunc\u001b[39m.\u001b[39;49mnout,\n\u001b[1;32m     88\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m     89\u001b[0m     dataset_join\u001b[39m=\u001b[39;49mdataset_join,\n\u001b[1;32m     90\u001b[0m     dataset_fill_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan,\n\u001b[1;32m     91\u001b[0m     kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m     92\u001b[0m     dask\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallowed\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     93\u001b[0m     keep_attrs\u001b[39m=\u001b[39;49m_get_keep_attrs(default\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     94\u001b[0m )\n",
      "File \u001b[0;32m~/bin/miniconda3/lib/python3.11/site-packages/xarray/core/computation.py:1270\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[39m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(a, DataArray) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args):\n\u001b[0;32m-> 1270\u001b[0m     \u001b[39mreturn\u001b[39;00m apply_dataarray_vfunc(\n\u001b[1;32m   1271\u001b[0m         variables_vfunc,\n\u001b[1;32m   1272\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m   1273\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m   1274\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m   1275\u001b[0m         exclude_dims\u001b[39m=\u001b[39;49mexclude_dims,\n\u001b[1;32m   1276\u001b[0m         keep_attrs\u001b[39m=\u001b[39;49mkeep_attrs,\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[1;32m   1278\u001b[0m \u001b[39m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(a, Variable) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args):\n",
      "File \u001b[0;32m~/bin/miniconda3/lib/python3.11/site-packages/xarray/core/computation.py:316\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[0;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[1;32m    311\u001b[0m result_coords, result_indexes \u001b[39m=\u001b[39m build_output_coords_and_indexes(\n\u001b[1;32m    312\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[39m=\u001b[39mkeep_attrs\n\u001b[1;32m    313\u001b[0m )\n\u001b[1;32m    315\u001b[0m data_vars \u001b[39m=\u001b[39m [\u001b[39mgetattr\u001b[39m(a, \u001b[39m\"\u001b[39m\u001b[39mvariable\u001b[39m\u001b[39m\"\u001b[39m, a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m--> 316\u001b[0m result_var \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mdata_vars)\n\u001b[1;32m    318\u001b[0m out: \u001b[39mtuple\u001b[39m[DataArray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m|\u001b[39m DataArray\n\u001b[1;32m    319\u001b[0m \u001b[39mif\u001b[39;00m signature\u001b[39m.\u001b[39mnum_outputs \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/bin/miniconda3/lib/python3.11/site-packages/xarray/core/computation.py:825\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[39mif\u001b[39;00m vectorize:\n\u001b[1;32m    821\u001b[0m         func \u001b[39m=\u001b[39m _vectorize(\n\u001b[1;32m    822\u001b[0m             func, signature, output_dtypes\u001b[39m=\u001b[39moutput_dtypes, exclude_dims\u001b[39m=\u001b[39mexclude_dims\n\u001b[1;32m    823\u001b[0m         )\n\u001b[0;32m--> 825\u001b[0m result_data \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49minput_data)\n\u001b[1;32m    827\u001b[0m \u001b[39mif\u001b[39;00m signature\u001b[39m.\u001b[39mnum_outputs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    828\u001b[0m     result_data \u001b[39m=\u001b[39m (result_data,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reanalysis_wind_U_nc = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_U10m_horario_2000a2010_uy.nc')\n",
    "reanalysis_wind_V_nc = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_V10m_horario_2000a2010_uy.nc')\n",
    "reanalysis_wind_U_2_nc = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_U10m_horario_2011a2021_uy.nc')\n",
    "reanalysis_wind_V_2_nc = xr.open_dataset('../Archivos_reanalisisERA5_realesINUMET/Reanalisis/Datos_V10m_horario_2011a2021_uy.nc')\n",
    "\n",
    "\n",
    "def transform_reanalysis_wind(U_nc, V_nc):\n",
    "    reanalysis = pd.DataFrame()\n",
    "    reanalysis['time'] = pd.to_datetime(U_nc.time)\n",
    "    reanalysis['sfcWind'] = np.sqrt(np.square(U_nc.u10) + np.square(V_nc.v10)) \\\n",
    "                               .mean(dim=[\"latitude\",\"longitude\"]) \n",
    "    reanalysis = reanalysis.loc[reanalysis[\"time\"] < datetime.fromisoformat('2015-01-01T00:00:00')]\n",
    "    reanalysis['date'] = reanalysis['time'].dt.date\n",
    "    reanalysis['day'] = reanalysis['time'].dt.day\n",
    "    reanalysis['month'] = reanalysis['time'].dt.month\n",
    "    reanalysis_by_day = reanalysis[[\"date\", \"sfcWind\"]].groupby('date') \\\n",
    "                                                   .mean() \\\n",
    "                                                   .rename(columns={\"sfcWind\":\"sfcWind_daily\"})\n",
    "    reanalysis = reanalysis.join(reanalysis_by_day, on=\"date\") \\\n",
    "                            .drop('date', axis=1)\n",
    "    return reanalysis\n",
    "\n",
    "reanalysis_wind = pd.concat([transform_reanalysis_wind(reanalysis_wind_U_nc, reanalysis_wind_V_nc), \n",
    "                             transform_reanalysis_wind(reanalysis_wind_U_2_nc, reanalysis_wind_V_2_nc)])\n",
    "\n",
    "reanalysis_wind = reanalysis_wind[((reanalysis_wind['day'] != 29) | (reanalysis_wind['month'] != 2))] #Delete all Feb 29th \n",
    "reanalysis_wind = reanalysis_wind[['time', 'sfcWind_daily', 'sfcWind']] #select the variables we want to keep\n",
    "reanalysis_wind.to_csv('reanalysis_sfcWind_training_data.csv',  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data to be downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CESM2_WACCM_wind_nc = xr.open_dataset('../data/sfcWind_day_CESM2-WACCM_historical_r1i1p1f1_gn_20000101-20141231_v20190227.nc')\n",
    "CESM2_WACCM_wind = pd.DataFrame()\n",
    "CESM2_WACCM_wind['time'] = CESM2_WACCM_wind_nc.time\n",
    "CESM2_WACCM_wind['CESM2_WACCM'] = CESM2_WACCM_wind_nc.sfcWind.mean(dim=[\"lat\",\"lon\"])\n",
    "CESM2_WACCM_wind['time'] = CESM2_WACCM_wind['time'].apply(lambda x: datetime.fromisoformat(x.isoformat()))\n",
    "\n",
    "CESM2_WACCM_wind_by_hour = []\n",
    "\n",
    "for row in CESM2_WACCM_wind.values:\n",
    "    for h in range(0,24):\n",
    "        new_row = pd.Series({\n",
    "            'time': row[0] + timedelta(hours=h),\n",
    "            'sfcWind': 0,\n",
    "            'sfcWind_daily': row[1]\n",
    "        })\n",
    "        CESM2_WACCM_wind_by_hour.append(new_row)\n",
    "\n",
    "CESM2_WACCM_wind = pd.DataFrame(CESM2_WACCM_wind_by_hour)\n",
    "CESM2_WACCM_wind.to_csv('cmip6_sfcWind_to_downscale_data.csv', index=False)\n",
    "#CESM2_WACCM_wind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECIPTITATION_FOLDER = \"../Archivos_reanalisisERA5_realesINUMET/Reanalisis-precipitation/\"\n",
    "\n",
    "def transform_reanalysis(data_nc):\n",
    "    reanalysis = pd.DataFrame()\n",
    "    try:\n",
    "        reanalysis['time'] = pd.to_datetime(data_nc.time)\n",
    "        reanalysis['pr'] = data_nc.tp.sum(dim=[\"latitude\",\"longitude\"])\n",
    "    except:\n",
    "        return reanalysis\n",
    " #   reanalysis = reanalysis.loc[reanalysis[\"time\"] < datetime.fromisoformat('2015-01-01T00:00:00')]\n",
    "    reanalysis['date'] = reanalysis['time'].dt.date\n",
    "    reanalysis['day'] = reanalysis['time'].dt.day\n",
    "    reanalysis['month'] = reanalysis['time'].dt.month\n",
    "    reanalysis_by_day = reanalysis[[\"date\", \"pr\"]].groupby('date') \\\n",
    "                                                   .sum() \\\n",
    "                                                   .rename(columns={\"pr\":\"pr_daily\"})\n",
    "    reanalysis = reanalysis.join(reanalysis_by_day, on=\"date\") \\\n",
    "                            .drop('date', axis=1)\n",
    "    return reanalysis\n",
    "\n",
    "reanalysis = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(PRECIPTITATION_FOLDER):\n",
    "\n",
    "    with zipfile.ZipFile(PRECIPTITATION_FOLDER + file,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(PRECIPTITATION_FOLDER + \"data\")\n",
    "    \n",
    "    precipitation_nc = xr.open_dataset(PRECIPTITATION_FOLDER + \"data/data.nc\")\n",
    "    df = transform_reanalysis(precipitation_nc)\n",
    "    reanalysis = pd.concat([reanalysis, df])\n",
    "    os.remove(PRECIPTITATION_FOLDER + \"data/data.nc\")\n",
    "    os.removedirs(PRECIPTITATION_FOLDER + \"data\")\n",
    "\n",
    "reanalysis.sort_values(by='time', inplace=True)\n",
    "reanalysis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reanalysis_temp = reanalysis[['time', 'pr_daily', 'pr']]\n",
    "reanalysis_temp.to_csv('reanalysis_precipitation.csv',  index=False)\n",
    "\n",
    "reanalysis = reanalysis.loc[reanalysis[\"time\"] < datetime.fromisoformat('2015-01-01T00:00:00')]\n",
    "reanalysis = reanalysis[((reanalysis['day'] != 29) | (reanalysis['month'] != 2))] #Delete all Feb 29th \n",
    "reanalysis = reanalysis[['time', 'pr_daily', 'pr']] #select the variables we want to keep\n",
    "reanalysis.to_csv('reanalysis_precipitation_training_data.csv',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210240"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reanalysis.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data to be downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CESM2_WACCM_precipitation_nc = xr.open_dataset('../data/pr_day_CESM2-WACCM_historical_r1i1p1f1_gn_20000101-20141231_v20190415.nc')\n",
    "CESM2_WACCM_precipitation = pd.DataFrame()\n",
    "CESM2_WACCM_precipitation['time'] = CESM2_WACCM_precipitation_nc.time\n",
    "CESM2_WACCM_precipitation['CESM2_WACCM'] = CESM2_WACCM_precipitation_nc.pr.sum(dim=[\"lat\",\"lon\"])*3600*24\n",
    "CESM2_WACCM_precipitation['time'] = CESM2_WACCM_precipitation['time'].apply(lambda x: datetime.fromisoformat(x.isoformat()))\n",
    "\n",
    "CESM2_WACCM_precipitation_by_hour = []\n",
    "\n",
    "for row in CESM2_WACCM_precipitation.values:\n",
    "    for h in range(0,24):\n",
    "        new_row = pd.Series({\n",
    "            'time': row[0] + timedelta(hours=h),\n",
    "            'pr': 0,\n",
    "            'pr_daily': row[1]\n",
    "        })\n",
    "        CESM2_WACCM_precipitation_by_hour.append(new_row)\n",
    "\n",
    "CESM2_WACCM_precipitation = pd.DataFrame(CESM2_WACCM_precipitation_by_hour)\n",
    "CESM2_WACCM_precipitation.to_csv('cmip6_precipitation_to_downscale_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURFACE_PRESSURE_FOLDER = \"../Archivos_reanalisisERA5_realesINUMET/Reanalisis-surface_pressure/\"\n",
    "\n",
    "def transform_reanalysis(data_nc):\n",
    "    reanalysis = pd.DataFrame()\n",
    "    try:\n",
    "        reanalysis['time'] = pd.to_datetime(data_nc.time)\n",
    "        reanalysis['sp'] = data_nc.sp.mean(dim=[\"latitude\",\"longitude\"])\n",
    "    except:\n",
    "        return reanalysis\n",
    "    reanalysis['date'] = reanalysis['time'].dt.date\n",
    "    reanalysis['day'] = reanalysis['time'].dt.day\n",
    "    reanalysis['month'] = reanalysis['time'].dt.month\n",
    "    reanalysis_by_day = reanalysis[[\"date\", \"sp\"]].groupby('date') \\\n",
    "                                                   .mean() \\\n",
    "                                                   .rename(columns={\"sp\":\"sp_daily\"})\n",
    "    reanalysis = reanalysis.join(reanalysis_by_day, on=\"date\") \\\n",
    "                            .drop('date', axis=1)\n",
    "    return reanalysis\n",
    "\n",
    "reanalysis = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(SURFACE_PRESSURE_FOLDER):\n",
    "\n",
    "    with zipfile.ZipFile(SURFACE_PRESSURE_FOLDER + file,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(SURFACE_PRESSURE_FOLDER + \"data\")\n",
    "    \n",
    "    surface_pressure_nc = xr.open_dataset(SURFACE_PRESSURE_FOLDER + \"data/data.nc\")\n",
    "    df = transform_reanalysis(surface_pressure_nc)\n",
    "    reanalysis = pd.concat([reanalysis, df])\n",
    "    os.remove(SURFACE_PRESSURE_FOLDER + \"data/data.nc\")\n",
    "    os.removedirs(SURFACE_PRESSURE_FOLDER + \"data\")\n",
    "\n",
    "reanalysis.sort_values(by='time', inplace=True)\n",
    "reanalysis.reset_index(drop=True, inplace=True)\n",
    "reanalysis = reanalysis[((reanalysis['day'] != 29) | (reanalysis['month'] != 2))] #Delete all Feb 29th \n",
    "reanalysis = reanalysis[['time', 'sp_daily', 'sp']] #select the variables we want to keep\n",
    "reanalysis = reanalysis.loc[reanalysis[\"time\"] < datetime.fromisoformat('2015-01-01T00:00:00')]\n",
    "reanalysis.to_csv('reanalysis_surface_pressure_training_data.csv',  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
