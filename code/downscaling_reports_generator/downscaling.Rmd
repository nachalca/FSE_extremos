---
title: "`r paste0('Downscaling the variable ', params$variable)`"
params:
  variable: "sfcWind" #Use pr as default
output: html_document
---

```{r setup, include=FALSE}
library(here)
knitr::opts_knit$set(root.dir = here())
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```

```{css}
/* Define a margin before h2 element */
h2,h3  {
  margin-top: 3em;
}
```

```{r imports}
library(ggplot2)
library(tidyverse)
library(knitr)
library(gridExtra)
Sys.setenv(RETICULATE_PYTHON = "/home/tancre/bin/miniconda3/bin/python")
library(reticulate)
library(yaml)
library("extremogram")
source('code/metrics.R')
source('code/utils.R')

#Load configuration
conf <- yaml.load_file("code/conf.yml")
```

```{r load_test_data}
x <- paste0('data/to_be_downscaled/', params$variable)
to_be_downscaled <- list.files(x)
```

```{r load_reanalyis}
reanalysis <- read.csv('data/reanalysis/reanalysis.csv')
reanalysis <- reanalysis |> 
  select(time, reanalysis = params$variable) 
if (!conf[["VARIABLES"]][[params$variable]][["daily"]]){
  reanalysis <- reanalysis |> 
                  mutate(time = getDate(time)) |>
                  group_by(time) |>
                  mutate(reanalysis = mean(reanalysis)) |>
                  ungroup() |>
                  unique()
}
```

```{r predictions, results=F}
xgb <- import_from_path("XgboostDownscaler", path = paste0(here(), "/code"))
xgboost_downscaler <- xgb$XgboostDownscaler()

cnn <- import_from_path("CNNDownscaler", path = paste0(here(), "/code"))
cnn_downscaler <- cnn$CNNDownscaler()

nv <- import_from_path("NaiveDownscaler", path = paste0(here(), "/code"))
nv_downscaler <- nv$NaiveDownscaler()

variable <- data.frame()
res <- list()
for(f in to_be_downscaled){
  #Load the data
  x <- paste0('data/to_be_downscaled/', params$variable,'/', f)
  variable <- read.csv(x)
  
  file_name <- unlist(strsplit(f, "\\."))[1]
  
  lab <- unlist(strsplit(file_name, "_"))[1]
  scenario <- paste0(unlist(strsplit(file_name, "_"))[2], 
                     unlist(strsplit(file_name, "_"))[3], 
                     unlist(strsplit(file_name, "_"))[4]
                     )
    
  xgboost_predictions <- xgboost_downscaler$predict(
                            model = paste0(here(), "/models/", params$variable, "/xgboost.pkl"), 
                            data = paste0(here(), "/", x)
                          )
  
  # cnn_predictions <- cnn_downscaler$predict(
  #                           model = paste0(here(), "/models/", params$variable, "/cnn.pkl"), 
  #                           data = paste0(here(), "/", x)
  #                         )
  
  nv_predictions <- nv_downscaler$predict(
                           model = paste0(here(), "/models/", params$variable, "/naive.pkl"), 
                           data = paste0(here(), "/", x)
                    )  
  
  variable <- variable |> filter(time %in% xgboost_predictions$time)
  res[[paste0("undownscaled.", lab, '_', scenario)]] <- variable[[params$variable]] 
  res[[paste0("xgboost.", lab, '_', scenario)]]  <- xgboost_predictions[["xgboost"]]
  #res[[paste0("cnn.", lab, '_', scenario)]]  <- cnn_predictions[["cnn"]][1:length(variable[[params$variable]] )] #TODO: CHECK DIMENSIONS
  res[[paste0("nv.", lab, '_', scenario)]] <- nv_predictions[["naive"]]
  #rm(variable)
}

```

```{r result_data, results=F}
res_wide <- as.data.frame(res) |> 
  mutate(time =  variable$time)

res_validation_wide <- reanalysis |> 
  inner_join(res_wide)

res_prediction_wide <- res_wide |> 
  filter(!(time %in% res_validation_wide$time))


res_long <- as.data.frame(res) |> 
  mutate(time =  variable$time) |>
  pivot_longer(-c("time"), names_to="model", values_to="value") |>
  separate(col = model, sep = "\\.", into = c("model", "experiment"))
  
res_validation_long <- reanalysis |> 
  inner_join(res_long)

res_prediction_long <- res_long |> 
  filter(!(time %in% res_validation_long$time))

#rm(res_df, res)
```

```{r metrics}
models <- res_validation_wide |> select(-c("time", "reanalysis", starts_with('undownscaled'))) |> colnames()

r <- lapply(models, function(x) {
    if (conf[["VARIABLES"]][[params$variable]][["daily"]]) {
      metrics_unpaired_hourly(time = res_validation_wide$time, truth = res_validation_wide$reanalysis, estimate = res_validation_wide[[x]], model = x)
    } else {
      metrics_unpaired_daily(time = res_validation_wide$time, truth = res_validation_wide$reanalysis, estimate = res_validation_wide[[x]], model = x)
    }
})

results <- do.call(rbind, r)

results <- results |>
  arrange(by = abs(diff_of_means)) |>
  mutate(diff_of_means = sprintf("%.2f%%", diff_of_means)) |>
  mutate(across(where(is.numeric), round, digits = 3)) 

kable(results)
```

### Time series of the first days

```{r show_plot, echo=FALSE, fig.height=9, fig.width=9}
days <- n_distinct(res_validation_long$model)*n_distinct(res_validation_long$experiment)*24*5
res_to_plot <- res_validation_long[0:days,]


series_plot <- function(data, exp) {
  p <- data |> 
    filter(experiment == exp) |>
    mutate(time = as.POSIXct(time))
  
  p2 <- p |>
      group_by(time) |>
      summarise(model = "reanalysis", value = mean(reanalysis))
  
  p <- p |> 
    select(time,model,value) |>
    rbind(p2) |>
    arrange(time)
  
    ### Assign black color to reanalyis
    gg_color_hue <- function(n) {
      hues = seq(15, 375, length = n + 1)
      hcl(h = hues, l = 65, c = 100)[1:n]
    } 
    
    pal <- gg_color_hue(4)
    pal[which(sort(unique(p$model)) == "reanalysis") ] <- "black"
    ##############################  

    ggplot(p, aes(x=time, y=value, color=model)) +
      geom_line() +
      scale_color_manual(values=pal) +
      labs(y = params$variable, x = "", title = exp)
}

# Serie to compare to reanalysis
models <- unique(res_validation_long$experiment)

# Generate Q-Q plots
plots <- lapply(models, function(exp) series_plot(res_to_plot, exp))

# Arrange the plots using gridExtra
do.call(grid.arrange, c(plots, ncol = 3))
```

`r  if (conf[["VARIABLES"]][[params$variable]][["daily"]]) {"### How Often Peaks Hit Hourly\n"} else {"### Distribution of daily values by month\n"}`

```{r maximum, fig.height=9, fig.width=9}
models <- unique(res_validation_long$experiment)

if (!conf[["VARIABLES"]][[params$variable]][["daily"]]) {
  
  plots <- lapply(models, function(col) {
    maximum_histograms(res_validation$time, 
                       res_validation$reanalysis, 
                       res_validation[[col]]) 
                        + scale_fill_discrete(labels = c(col, "reanalysis"))
  })
  
  do.call(grid.arrange, c(plots, ncol = 3))

} else {
    plots <- lapply(models, function(exp) {
  
      p <- res_validation_long |> 
        filter(experiment == exp) 
  
      p2 <- p |>
          group_by(time) |>
          summarise(model = "reanalysis", value = mean(reanalysis))
      
      p <- p |> 
        select(time,model,value) |>
        rbind(p2) |>
        arrange(time)
            
      monthly_boxplot_2(p)
  })
  do.call(grid.arrange, c(plots, ncol = 2))
}
```

### QQ Plot

```{r qqplot, fig.height=8, fig.width=6}
# Function to create a Q-Q plot comparing quantiles of a sample column against a reference column
qq_plot_against <- function(data, sample_col) {
  ref_col <- "reanalysis"
  sample_data <- data[[sample_col]]
  ref_data <- data[[ref_col]]
  
  # Sort the data
  sample_data_sorted <- sort(sample_data)
  ref_data_sorted <- sort(ref_data)
  
  # Calculate quantiles
  n <- min(length(sample_data_sorted), length(ref_data_sorted))
  quantiles_sample <- sample_data_sorted[seq(1, length(sample_data_sorted), length.out = n)]
  quantiles_ref <- ref_data_sorted[seq(1, length(ref_data_sorted), length.out = n)]
  
  # Create a data frame for plotting
  quantile_df <- data.frame(Quantiles_Ref = quantiles_ref, Quantiles_Sample = quantiles_sample)
  
  # Generate the Q-Q plot
  ggplot(quantile_df, aes(x = Quantiles_Ref, y = Quantiles_Sample)) +
    geom_point() +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    ggtitle(paste(sample_col)) +
    labs(x = NULL, y = NULL) +
    theme_minimal()
}

# Columns to compare against the reference column
models <- res_validation |> select(-c("time", "reanalysis", starts_with('undownscaled_'))) |> colnames()
# Generate Q-Q plots
plots <- lapply(models, function(col) qq_plot_against(res_validation, col))

# Arrange the plots using gridExtra
do.call(grid.arrange, c(plots, ncol = 2))  # Arrange in a grid
```

### Autocorrelogram

```{r acf}
models <- res_validation_wide |> select(-c("time",  starts_with('undownscaled'))) |> colnames()
r <- lapply(models, function(x) {
  acf(res_validation_wide[[x]], lag.max = 47, plot = F)$acf
})

results <- do.call(cbind, r)

colnames(results) <- models

results <- as_data_frame(results)

results <- results |> pivot_longer(cols = everything(), names_to = "model", values_to = "acf")
results$lag <- sort(rep(1:48, length(models)))

results <- results |> filter(lag > 1) #I don't want to plot the first lag

ggplot(results, mapping = aes(x = lag, y = acf)) +
    geom_segment(mapping = aes(xend = lag, yend = 0)) +
    facet_wrap(~ model, ncol = 3) 
```

### Extremogram

```{r extremogram}
models <- res_validation_wide |> select(-c("time", starts_with('undownscaled'))) |> colnames()

r <- lapply(models, function(x) {
  extremogram1(res_validation_wide[[x]], quant = .97, maxlag = 48, type = 1, ploting = 0)
})

results <- do.call(cbind, r)

colnames(results) <- models

results <- as_data_frame(results)

results <- results |> pivot_longer(cols = everything(), names_to = "model", values_to = "extremogram")
results$lag <- sort(rep(1:48, length(models)))

results <- results |> filter(lag > 1) #I don't want to plot the first lag

ggplot(results, mapping = aes(x = lag, y = extremogram)) +
    geom_segment(mapping = aes(xend = lag, yend = 0)) +
    facet_wrap(~ model, ncol = 3)
```