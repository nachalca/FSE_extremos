{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 13:37:48.897564: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-15 13:37:49.100152: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-15 13:37:49.685328: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 13:37:51.731769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "SEED = 123  # used to help randomly select the data points\n",
    "DATA_SPLIT_PCT = 0.2\n",
    "\n",
    "df = pd.read_csv(\"reanalysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical column to hot dummy columns\n",
    "hotencoding1 = pd.get_dummies(df['month'])\n",
    "hotencoding1 = hotencoding1.add_prefix('month')\n",
    "hotencoding2 = pd.get_dummies(df['hour'])\n",
    "hotencoding2 = hotencoding2.add_prefix('hour')\n",
    "\n",
    "df=df.drop(['month', 'hour'], axis=1)\n",
    "\n",
    "df=pd.concat([df, hotencoding1, hotencoding2], axis=1)\n",
    "\n",
    "# Rename response column name for ease of understanding\n",
    "df=df.rename(columns={'sfcWind':'y'})\n",
    "\n",
    "#Filter the rows with time less than 2015-01-01\n",
    "df_train = df[df['time'] < '2013-12-31 23:59:00']\n",
    "df_test = df[df['time'] >= '2013-12-31 23:59:00']\n",
    "\n",
    "df_train = df_train.set_index('time')\n",
    "df_test = df_test.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X_train = df_train.loc[:, df_train.columns != 'y'].values  # converts df to numpy array\n",
    "input_X_test = df_test.loc[:, df_test.columns != 'y'].values  \n",
    "input_y_train = df_train['y'].values\n",
    "input_y_test = df_test['y'].values\n",
    "\n",
    "n_features = input_X_train.shape[1]  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalize(X, y, lookback):\n",
    "    '''\n",
    "    Inputs\n",
    "    X         A 2D numpy array ordered by time of shape: (n_observations x n_features)\n",
    "    y         A 1D numpy array with indexes aligned with X, i.e. y[i] should correspond to X[i]. Shape: n_observations.\n",
    "    lookback  The window size to look back in the past records. Shape: a scalar.\n",
    "\n",
    "    Output\n",
    "    output_X  A 3D numpy array of shape: ((n_observations-lookback-1) x lookback x n_features)\n",
    "    output_y  A 1D array of shape: (n_observations-lookback-1), aligned with X.\n",
    "    '''\n",
    "    output_X = []\n",
    "    output_y = []\n",
    "    for i in range(len(X) - lookback - 1):\n",
    "        t = []\n",
    "        for j in range(1, lookback + 1):\n",
    "            # Gather the past records upto the lookback period\n",
    "            t.append(X[[(i + j + 1)], :])\n",
    "        output_X.append(t)\n",
    "        output_y.append(y[i + lookback + 1])\n",
    "    return np.squeeze(np.array(output_X)), np.array(output_y)\n",
    "\n",
    "def flatten(X):\n",
    "    '''\n",
    "    Flatten a 3D array.\n",
    "\n",
    "    Input\n",
    "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
    "\n",
    "    Output\n",
    "    flattened_X  A 2D array, sample x features.\n",
    "    '''\n",
    "    flattened_X = np.empty(\n",
    "        (X.shape[0], X.shape[2]))  # sample x features array.\n",
    "    for i in range(X.shape[0]):\n",
    "        flattened_X[i] = X[i, (X.shape[1] - 1), :]\n",
    "    return flattened_X\n",
    "\n",
    "def scale(X, scaler):\n",
    "    '''\n",
    "    Scale 3D array.\n",
    "\n",
    "    Inputs\n",
    "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
    "    scaler       A scaler object, e.g., sklearn.preprocessing.StandardScaler, sklearn.preprocessing.normalize\n",
    "\n",
    "    Output\n",
    "    X            Scaled 3D array.\n",
    "    '''\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i, :, :] = scaler.transform(X[i, :, :])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 5\n",
    "X_train, y_train = temporalize(X=input_X_train, \n",
    "                      y=input_y_train, \n",
    "                      lookback=lookback)\n",
    "X_test, y_test = temporalize(X=input_X_test, \n",
    "                      y=input_y_test, \n",
    "                      lookback=lookback)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=DATA_SPLIT_PCT,\n",
    "    random_state=SEED)\n",
    "\n",
    "TIMESTEPS = X_train.shape[1]  # equal to the lookback\n",
    "N_FEATURES = X_train.shape[2]  # the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a scaler using the training data.\n",
    "scaler = StandardScaler().fit(flatten(X_train))\n",
    "X_train_scaled = scale(X_train, scaler)\n",
    "X_valid_scaled = scale(X_valid, scaler)\n",
    "X_test_scaled =  scale(X_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_layer_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m3,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,777</span> (18.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,777\u001b[0m (18.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,777</span> (18.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,777\u001b[0m (18.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(TIMESTEPS, N_FEATURES), \n",
    "                name='input'))\n",
    "model.add(\n",
    "    LSTM(units=16, \n",
    "         activation='tanh',\n",
    "         recurrent_activation='sigmoid',\n",
    "         return_sequences=True, \n",
    "         name='lstm_layer_1'))\n",
    "model.add(\n",
    "    LSTM(units=8, \n",
    "         activation='tanh', \n",
    "         recurrent_activation='sigmoid',\n",
    "         return_sequences=False, \n",
    "         name='lstm_layer_2'))\n",
    "model.add(Dense(units=1, \n",
    "                activation='linear', \n",
    "                name='output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.RootMeanSquaredError()\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 13:38:20.390650: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 88279200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x= np.asarray(X_train_scaled).astype('float32'),\n",
    "                    y=y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=100,\n",
    "                    validation_data=(np.asarray(X_valid_scaled).astype('float32'), \n",
    "                                     y_valid),\n",
    "                    verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(np.asarray(X_test_scaled).astype('float32'))\n",
    "res = pd.DataFrame(p)\n",
    "res.to_csv(\"lstm_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
